{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Plan\n",
    "For every algorithm developed it is important to design some test cases that the algorithm should pass. For an algorithm that generates summaries that can be slightly difficult. For systems that take input from one known language to another there are established techniques that are avalable but for our project we need to come up with something different. The solution we came up with for his is to generate test cases \"on the fly\" and prompt a user to reverse the given summary for comparison. We do this by generating (or reading in) some sentences, summarizing these sentences, and then comparing the human guess as to what the emojis mean to the input sentence. The general flow for this process is as follows\n",
    "\n",
    "   1. Generate (or read) sentences\n",
    "   2. Summarize each of the sentences\n",
    "   3. Take the top 20 sentences, sorted by the certainty score\n",
    "   4. For each machine translated sentence:\n",
    "       1. Provide the user with the emojis\n",
    "       2. Provide the user with an approximate sentence length\n",
    "       3. Prompt the user to tranlate the emojis into a sentence\n",
    "   5. For each machine translated sentence-user translated sentence pair:\n",
    "       1. Calculate the distance between the two sentences using sent2vec (might need another metric)\n",
    "\n",
    "After we have the list of numerical scores for the translations we can do some analysis on how the algorithm actually performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation\n",
    "The sentences are gathered from the [Stanford NLP research group's NMT dataset](https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.en). All of these sentences will be loaded into memory, filtered based on length, and cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 sentences in dataset\n"
     ]
    }
   ],
   "source": [
    "# Load the sentences\n",
    "file_path = \"data/tst2012.en\"\n",
    "testing_sentences = []\n",
    "with open(file_path, \"r\") as sents:\n",
    "    testing_sentences = [sent for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the sentences based on an upper and lower bound for the sentence length\n",
    "from nltk import word_tokenize\n",
    "word_limit_lower = 5\n",
    "word_limit_upper = 5\n",
    "testing_sentences = list(filter(lambda sent: len(word_tokenize(sent)) <= word_limit_upper and \n",
    "                                             len(word_tokenize(sent)) >= word_limit_lower, testing_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the sentences have \"&apos;\" instead of \"'\" but our algorithm doesn't handle that so replace with\n",
    "# regular \"'\"\n",
    "testing_sentences = [testing_sentence.replace(\"&apos;\", \"'\") for testing_sentence in testing_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query how many sentences are in the current dataset\n",
    "print(f\"{len(testing_sentences)} sentences in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Summarization\n",
    "To do this we will just be using an exported Python V1 program that is just the NaiveEmojiTranslation notebook exported to .py. We summarize with the current best known params based on some limited observation. The sentence will be summarized using the best currently known parameters, and then the summaries scored based on the scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')               # cosine distance gives warnings when div by 0\n",
    "from NaiveEmojiTranslation_V1 import summarize, lemmatizerNLTK # Exported NaiveEmojiTranslation to Python file as of October 24th\n",
    "\n",
    "# Sort the sentences by their uncertainty scores. This is imported as a generic scoring\n",
    "# function so that it can be swapped in and out easily\n",
    "from NaiveEmojiTranslation_V1 import score_summarization_result_average as scoring_function\n",
    "\n",
    "# JUST FOR TESTING ONLY USE TEN\n",
    "testing_sentences = testing_sentences[:10]\n",
    "\n",
    "# Summarize each testing sentence with the current best known parameters\n",
    "summarized_sentences = []\n",
    "for sentence in testing_sentences:\n",
    "    summarized_sentences.append(summarize(sentence, keep_stop_words=True, \n",
    "                                  lemma_func=lemmatizerNLTK.lemmatize, scoring_func=scoring_function))\n",
    "    \n",
    "# Sort the list by the scoring function\n",
    "summarized_sentences_sorted = list(sorted(summarized_sentences, key=scoring_function))\n",
    "\n",
    "# Choose only the top 30 summaries\n",
    "testing_summaries = summarized_sentences_sorted[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NaiveEmojiTranslation_V1 import EmojiSummarizationResult\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class UserSummarization:\n",
    "    \"\"\"\n",
    "    Struct-esque data structure that stores the machines summarization and the user's guess in one object.\n",
    "    This is just syntactic sugar for a python object with some default values and type checking.\n",
    "    \"\"\"\n",
    "    machine_summarization: EmojiSummarizationResult\n",
    "    user_guess: str = \"\"\n",
    "    difference: float = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all generated summaries\n",
    "user_summaries = []\n",
    "for summary in summarized_sentences_sorted:\n",
    "    # Give the user the emoji summary and the input sentence length to shoot for in summary\n",
    "    print(f\"Emoji Sequence: {summary.emojis}\")\n",
    "    print(\"Input sentence Length: {}\".format(len(word_tokenize(\" \".join(summary.n_grams)))))\n",
    "    \n",
    "    # Prompt the user for their translation\n",
    "    translation = input(\"What's your translation?\")\n",
    "    \n",
    "    # Append a new UserSummarization object with the machines summary and the users translation to the list\n",
    "    user_summaries.append(UserSummarization(summary, translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "This is soon to change so not gonna mess with it too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sent2vec model\n",
    "import sent2vec\n",
    "s2v = sent2vec.Sent2vecModel()\n",
    "s2v.load_model('../models/wiki_unigrams.bin') # https://drive.google.com/open?id=0B6VhzidiLvjSa19uYWlLUEkzX3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emojis: üôè\n",
      "User guessed: You're the best\n",
      "Summary Input: thank you very much\n",
      "Difference: 1.0038026724942029\n",
      "\n",
      "Emojis: üôè\n",
      "User guessed: Thank you so much\n",
      "Summary Input: thank you very much\n",
      "Difference: 0.5063760280609131\n",
      "\n",
      "Emojis: üö•üåé\n",
      "User guessed: stop and go see the world\n",
      "Summary Input: go home to where\n",
      "Difference: 0.7362043857574463\n",
      "\n",
      "Emojis: üò∂\n",
      "User guessed: he was very quiet\n",
      "Summary Input: he retreated into silence\n",
      "Difference: 0.6807082295417786\n",
      "\n",
      "Emojis: ‚ôì\n",
      "User guessed: the fish is good\n",
      "Summary Input: there were still fish\n",
      "Difference: 0.5206278562545776\n",
      "\n",
      "Emojis: üÜò\n",
      "User guessed: save our souls help\n",
      "Summary Input: so what happens here\n",
      "Difference: 0.8867711946368217\n",
      "\n",
      "Emojis: üë§\n",
      "User guessed: I\n",
      "Summary Input: something stiffened inside me\n",
      "Difference: nan\n",
      "\n",
      "Emojis: üíØüõÖ\n",
      "User guessed: a good trip\n",
      "Summary Input: after only one trip\n",
      "Difference: 0.46960216760635376\n",
      "\n",
      "Emojis: üë™\n",
      "User guessed: family\n",
      "Summary Input: he is my grandfather\n",
      "Difference: 0.7951625138521194\n",
      "\n",
      "Emojis: üöØüáßüá™\n",
      "User guessed: dont be \n",
      "Summary Input: it would be unconscionable\n",
      "Difference: 0.7098469436168671\n",
      "\n",
      "\n",
      "Average cosine difference  0.630910199182108\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine # Distance between sentence and emoji in sent2vec vector space\n",
    "import numpy as np\n",
    "\n",
    "for user_summary in user_summaries:\n",
    "    user_emb, mach_emb = s2v.embed_sentences([user_summary.user_guess, \" \".join(user_summary.machine_summarization.n_grams)])\n",
    "    user_summary.difference = cosine(user_emb, mach_emb)\n",
    "    print(\"Emojis: {}\\nUser guessed: {}\\nSummary Input: {}\\nDifference: {}\".format(user_summary.machine_summarization.emojis, user_summary.user_guess, \" \".join(user_summary.machine_summarization.n_grams), user_summary.difference))\n",
    "    print()\n",
    "    \n",
    "print()\n",
    "print(\"Average cosine difference \", sum([user_summary.difference for user_summary in user_summaries \n",
    "                                         if not np.isnan(user_summary.difference)]) / len(user_summaries))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
